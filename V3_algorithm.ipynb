{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_bbox(img,bbox_image):\n",
    "    contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        \n",
    "        # # Debugging statements\n",
    "        # if area > 1:\n",
    "        #     print(\"Area of contour is: {}\".format(area))\n",
    "        \n",
    "        areaMin = 15\n",
    "        areaMax = 100\n",
    "        if area > areaMin and area < areaMax:\n",
    "            M = cv2.moments(cnt)\n",
    "            if M['m00'] != 0:\n",
    "                cx = int(M['m10']/M['m00'])\n",
    "                cy = int(M['m01']/M['m00'])\n",
    "            else:\n",
    "                cx = 0\n",
    "                cy = 0\n",
    "            print(cx, cy)\n",
    "            # cv2.drawContours(bbox_image, cnt, -1, (255, 0, 255), 7)\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "            # print(len(approx))\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            cv2.rectangle(bbox_image, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
    "            # cv2.circle(bbox_image, (cx, cy), 7, (0,255,0), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_creation(source_image, overlay):\n",
    "    lines = cv2.HoughLinesP(source_image, rho=6, theta=np.pi / 2, threshold=160, lines=np.array([]), minLineLength=40, maxLineGap=4)\n",
    "\n",
    "    overlay_image = cv2.cvtColor(overlay, cv2.COLOR_GRAY2RGB)\n",
    "    houghline = overlay_image.copy()\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            \n",
    "            start_point = (line[0][0], line[0][1]) # represents the top left corner of image\n",
    "            end_point = (line[0][2], line[0][3]) # represents the bottom right corner of image\n",
    "            color = (0, 255, 0) # Green color in BGR\n",
    "            thickness = 2 # Line thickness\n",
    "                \n",
    "            cv2.line(houghline, start_point, end_point, color, thickness)\n",
    "    \n",
    "    return houghline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROI_creation(source_image, row_start, row_end, col_start, col_end):\n",
    "    ROI_frame = source_image[row_start:row_end, col_start:col_end] #old one was [94:348, 166:275]\n",
    "    ROI_image = np.zeros_like(source_image)\n",
    "    x = row_start \n",
    "    y = col_start \n",
    "    for i in range(0, row_end-row_start):\n",
    "        for j in range(0, col_end-col_start):\n",
    "            if ROI_frame[i][j] != 0:\n",
    "                ROI_image[x + i, y + j] = ROI_frame[i, j]\n",
    "    return ROI_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_creation2(source_image, overlay):\n",
    "    \n",
    "    lines = cv2.HoughLinesP(source_image, rho=6, theta=np.pi / 2, threshold=160, lines=np.array([]), minLineLength=40, maxLineGap=4)\n",
    "    overlay_image = cv2.cvtColor(overlay, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    houghline = overlay_image.copy()\n",
    "    houghcircle = overlay_image.copy()\n",
    "    \n",
    "    length_line_list = []\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "\n",
    "            x1 = line[0][0]\n",
    "            y1 = line[0][1]\n",
    "            x2 = line[0][2]\n",
    "            y2 = line[0][3]\n",
    "\n",
    "            start_point = (x1, y1)\n",
    "            end_point = (x2, y2)\n",
    "            \n",
    "            lengthOfLine = math.sqrt(abs(x2-x1)^2 + abs(y2-y1)^2)\n",
    "            length_line_list.append(lengthOfLine)\n",
    "\n",
    "        index_number = length_line_list.index(max(length_line_list))\n",
    "\n",
    "        x1 = lines[index_number][0][0]\n",
    "        y1 = lines[index_number][0][1]\n",
    "        x2 = lines[index_number][0][2]\n",
    "        y2 = lines[index_number][0][3]\n",
    "\n",
    "        start_point = (x1, y1)\n",
    "        end_point = (x2, y2)\n",
    "\n",
    "        color = (0, 255, 0) # Green color in BGR\n",
    "        thickness = 2 # Line thickness of 9 px\n",
    "        radius = 5 #circle radius\n",
    "\n",
    "        cv2.line(houghline, start_point, end_point, color, thickness)\n",
    "        cv2.circle(houghcircle, end_point, radius, color, thickness)\n",
    "    \n",
    "    return houghline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def needle_tip_estimation(source_image, overlay):\n",
    "    \n",
    "    lines = cv2.HoughLinesP(source_image, rho=6, theta=np.pi / 2, threshold=160, lines=np.array([]), minLineLength=40, maxLineGap=4)\n",
    "    overlay_image = cv2.cvtColor(overlay, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    houghcircle = overlay_image.copy()\n",
    "    \n",
    "    length_line_list = []\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "\n",
    "            x1 = line[0][0]\n",
    "            y1 = line[0][1]\n",
    "            x2 = line[0][2]\n",
    "            y2 = line[0][3]\n",
    "            \n",
    "            lengthOfLine = math.sqrt(abs(x2-x1)^2 + abs(y2-y1)^2)\n",
    "            length_line_list.append(lengthOfLine)\n",
    "\n",
    "        index_number = length_line_list.index(max(length_line_list))\n",
    "\n",
    "        x1 = lines[index_number][0][0]\n",
    "        y1 = lines[index_number][0][1]\n",
    "        x2 = lines[index_number][0][2]\n",
    "        y2 = lines[index_number][0][3]\n",
    "\n",
    "        start_point = (x1, y1)\n",
    "\n",
    "        color = (0, 255, 0) # Green color in BGR\n",
    "        thickness = 2 # Line thickness of 9 px\n",
    "        radius = 5 #circle radius\n",
    "\n",
    "        cv2.circle(houghcircle, start_point, radius, color, thickness)\n",
    "    \n",
    "    return houghcircle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeedleVisualization:\n",
    "\n",
    "    def __init__(self, frame):\n",
    "        self.frame = frame\n",
    "        self.frameWidth = 440\n",
    "        self.frameHeight = 440\n",
    "        \n",
    "        #ROI parameters\n",
    "        self.rstart = 140 #previously 94\n",
    "        self.rend = 348\n",
    "        self. cstart = 195 #previously 166\n",
    "        self. cend = 235 #previously 275\n",
    "\n",
    "        #Initial Preprocessing\n",
    "        self.resized_frame = cv2.resize(self.frame, (self.frameWidth,self.frameHeight))\n",
    "        self.resized_frame = cv2.cvtColor(self.resized_frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "    def line_creation(self, source_image, overlay):\n",
    "        lines = cv2.HoughLinesP(source_image, rho=6, theta=np.pi / 2, threshold=160, lines=np.array([]), minLineLength=40, maxLineGap=4)\n",
    "\n",
    "        overlay_image = cv2.cvtColor(overlay, cv2.COLOR_GRAY2RGB)\n",
    "        houghline = overlay_image.copy()\n",
    "\n",
    "        if lines is not None:\n",
    "            for line in lines:\n",
    "                \n",
    "                start_point = (line[0][0], line[0][1]) # represents the top left corner of image\n",
    "                end_point = (line[0][2], line[0][3]) # represents the bottom right corner of image\n",
    "                color = (0, 255, 0) # Green color in BGR\n",
    "                thickness = 2 # Line thickness\n",
    "                    \n",
    "                cv2.line(houghline, start_point, end_point, color, thickness)\n",
    "        \n",
    "        return houghline\n",
    "\n",
    "    def line_creation2(self, source_image, overlay):\n",
    "        \n",
    "        lines = cv2.HoughLinesP(source_image, rho=6, theta=np.pi / 2, threshold=160, lines=np.array([]), minLineLength=40, maxLineGap=4)\n",
    "        overlay_image = cv2.cvtColor(overlay, cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        houghline = overlay_image.copy()\n",
    "        houghcircle = overlay_image.copy()\n",
    "        \n",
    "        length_line_list = []\n",
    "\n",
    "        if lines is not None:\n",
    "            for line in lines:\n",
    "\n",
    "                x1 = line[0][0]\n",
    "                y1 = line[0][1]\n",
    "                x2 = line[0][2]\n",
    "                y2 = line[0][3]\n",
    "\n",
    "                start_point = (x1, y1)\n",
    "                end_point = (x2, y2)\n",
    "                \n",
    "                lengthOfLine = math.sqrt(abs(x2-x1)^2 + abs(y2-y1)^2)\n",
    "                length_line_list.append(lengthOfLine)\n",
    "\n",
    "            index_number = length_line_list.index(max(length_line_list))\n",
    "\n",
    "            x1 = lines[index_number][0][0]\n",
    "            y1 = lines[index_number][0][1]\n",
    "            x2 = lines[index_number][0][2]\n",
    "            y2 = lines[index_number][0][3]\n",
    "\n",
    "            start_point = (x1, y1)\n",
    "            end_point = (x2, y2)\n",
    "            print(end_point)\n",
    "\n",
    "            color = (0, 255, 0) # Green color in BGR\n",
    "            thickness = 2 # Line thickness of 9 px\n",
    "            radius = 5 #circle radius\n",
    "    \n",
    "            cv2.line(houghline, start_point, end_point, color, thickness)\n",
    "            cv2.circle(houghcircle, end_point, radius, color, thickness)\n",
    "        \n",
    "        return houghline\n",
    "\n",
    "    def ROI_creation(source_image, row_start, row_end, col_start, col_end):\n",
    "        ROI_frame = source_image[row_start:row_end, col_start:col_end] #old one was [94:348, 166:275]\n",
    "        ROI_image = np.zeros_like(source_image)\n",
    "        x = row_start \n",
    "        y = col_start \n",
    "        for i in range(0, row_end-row_start):\n",
    "            for j in range(0, col_end-col_start):\n",
    "                if ROI_frame[i][j] != 0:\n",
    "                    ROI_image[x + i, y + j] = ROI_frame[i, j]\n",
    "        return ROI_image\n",
    "\n",
    "    \n",
    "    def detect_needle_line(self):\n",
    "\n",
    "        #Achieving desired region of interest within Raw Frame\n",
    "        ##############################################################\n",
    "        ROI_image = ROI_creation(self.resized_frame,self.rstart,self.rend,self.cstart,self.cend)\n",
    "        ##############################################################\n",
    "\n",
    "        #Applying Paper Algorithm Filters\n",
    "        #############################################################\n",
    "        # gabor_filter = cv2.getGaborKernel((6,6), sigma=0.5, theta=0, lambd=0.5, gamma=0.8, psi=0, ktype=cv2.CV_32F)\n",
    "        gabor_filter = cv2.getGaborKernel((3,3), sigma=0.95, theta=0, lambd=5, gamma=0.8, psi=0, ktype=cv2.CV_32F)\n",
    "        # gabor_filter = cv2.getGaborKernel((3,3), sigma=0.5, theta=0, lambd=30, gamma=0.8, psi=0, ktype=cv2.CV_32F)\n",
    "\n",
    "        gabor_output = cv2.filter2D(ROI_image, -1, gabor_filter)\n",
    "\n",
    "        #Binarized image is divided into grids for needle axis localization.\n",
    "        # - Median filter\n",
    "        median_filter = cv2.medianBlur(gabor_output, 7)\n",
    "        # - automatic thresholding\n",
    "        threshold = cv2.threshold(median_filter, 250, 255, cv2.THRESH_BINARY)[1]\n",
    "        # - morphological operations\n",
    "        element = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "        eroded = cv2.erode(threshold, element)\n",
    "        dilated = cv2.dilate(eroded, element)\n",
    "        #############################################################\n",
    "            \n",
    "        #Hough Line Transforms\n",
    "        #############################################################\n",
    "        houghline = line_creation(dilated, self.resized_frame)\n",
    "        #############################################################\n",
    "        return houghline\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#videos to choose from\n",
    "NeedleViz_path1 = 'Data/edited data/102622_Water.mp4'\n",
    "NeedleViz_path2 = 'Data/edited data/102822_Water.mp4'\n",
    "NeedleViz_oilAndLatex = 'Data/edited data/oil and latex/capture_5_2022-11-12T16-56-03.mp4'\n",
    "NeedleViz_gelAndLatex = 'Data/edited data/ultrasound gel and latex/capture_4_2022-11-12T17-33-19.mp4'\n",
    "NeedleViz_clarius1 = 'Data/edited data/clarius_FinalPrototype_needlejustWater.mp4'\n",
    "NeedleViz_clarius2 = 'Data/edited data/clarius_FinalPrototype_needlejustWater2.mp4'\n",
    "NeedleViz_clarius3 = 'Data/edited data/clarius_FinalPrototype_needleWithSolid.mp4'\n",
    "NeedleViz_clarius4 = 'Data/edited data/clarius_FinalPrototype_needleWithSolid2.mp4'\n",
    "NeedleViz_clarius5 = 'Data/edited data/clarius_FinalPrototype_needleWithSolid3.mp4'\n",
    "\n",
    "#control playback speed\n",
    "frame_rate = 30\n",
    "\n",
    "# vc = cv2.VideoCapture(0) #opens camera\n",
    "vc = cv2.VideoCapture(NeedleViz_clarius5)\n",
    "\n",
    "frameWidth = 440\n",
    "frameHeight = 440\n",
    "vc.set(3, frameWidth)\n",
    "vc.set(4, frameHeight)\n",
    "\n",
    "size = (frameWidth, frameHeight)\n",
    "\n",
    "#Preparing to create output videos\n",
    "image_lst = []\n",
    "\n",
    "if (vc.isOpened()== False): \n",
    "  print(\"Error opening video  file\")\n",
    "\n",
    "while(vc.isOpened()):\n",
    "    rval, frame = vc.read()\n",
    "    \n",
    "    if rval == True:\n",
    "\n",
    "        #Initial Frame preprocessing\n",
    "        ##############################################################\n",
    "        print(type(frame))\n",
    "        \n",
    "        resized_frame = cv2.resize(frame, (frameWidth,frameHeight))\n",
    "        resized_frame = cv2.cvtColor(resized_frame, cv2.COLOR_RGB2GRAY)\n",
    "        ##############################################################\n",
    "\n",
    "\n",
    "        #Achieving desired region of interest within Raw Frame\n",
    "        ##############################################################\n",
    "        rstart = 140 #previously 94\n",
    "        rend = 348\n",
    "        cstart = 195 #previously 166\n",
    "        cend = 235 #previously 275\n",
    "\n",
    "        ROI_image = ROI_creation(resized_frame,rstart,rend,cstart,cend)\n",
    "\n",
    "        #show the image \n",
    "        cv2.imshow(\"ROI image\", ROI_image)\n",
    "\n",
    "\n",
    "        ############################################################## \n",
    "      \n",
    "        #Applying Combination Filters\n",
    "        #############################################################\n",
    "        \n",
    "        ### THRESHOLDING ###\n",
    "        thresh = cv2.threshold(ROI_image, 90, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        ### BASIC MORPHOLOGICAL OPERATIONS ###\n",
    "        # dilate = cv2.dilate(thresh, None, iterations=1)\n",
    "        # erode = cv2.erode(dilate, None, iterations=1)\n",
    "        # dilate_2 = cv2.dilate(erode, None, iterations=1)\n",
    "\n",
    "        \n",
    "        ### ADVANCED MORPHOLIGICAL OPERATIONS (skeletonization) ###\n",
    "        skel_image = thresh.copy()\n",
    "\n",
    "        # Step 1: Create an empty skeleton\n",
    "        size = np.size(skel_image)\n",
    "        skel = np.zeros(skel_image.shape, np.uint8)\n",
    "\n",
    "        # Get a Cross Shaped Kernel\n",
    "        element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "\n",
    "        #Step 2: Open the image\n",
    "        open = cv2.morphologyEx(skel_image, cv2.MORPH_OPEN, element)\n",
    "        #Step 3: Substract open from the original image\n",
    "        temp = cv2.subtract(skel_image, open)\n",
    "        #Step 4: Erode the original image and refine the skeleton\n",
    "        eroded = cv2.erode(skel_image, element)\n",
    "        skel = cv2.bitwise_or(skel_image,temp)\n",
    "        skel_image = eroded.copy()\n",
    "\n",
    "        #new image show\n",
    "        cv2.imshow(\"skel_image\", skel_image)\n",
    "        #############################################################\n",
    "        \n",
    "        #Applying Edge and Bounding box detection\n",
    "        #############################################################\n",
    "        canny = cv2.Canny(skel_image, 73,200)\n",
    "\n",
    "        #new image\n",
    "        cv2.imshow(\"canny image\", canny)\n",
    "\n",
    "        bbox = resized_frame.copy()\n",
    "        # detect_bbox(canny,bbox)\n",
    "        #############################################################\n",
    "\n",
    "        #Applying Paper Algorithm Filters\n",
    "        #############################################################\n",
    "        # gabor_filter = cv2.getGaborKernel((6,6), sigma=0.5, theta=0, lambd=0.5, gamma=0.8, psi=0, ktype=cv2.CV_32F)\n",
    "        gabor_filter = cv2.getGaborKernel((3,3), sigma=0.95, theta=0, lambd=5, gamma=0.8, psi=0, ktype=cv2.CV_32F)\n",
    "        # gabor_filter = cv2.getGaborKernel((3,3), sigma=0.5, theta=0, lambd=30, gamma=0.8, psi=0, ktype=cv2.CV_32F)\n",
    "\n",
    "        gabor_output = cv2.filter2D(ROI_image, -1, gabor_filter)\n",
    "\n",
    "        #new image show\n",
    "        cv2.imshow(\"garbor output\", gabor_output)\n",
    "\n",
    "        #Binarized image is divided into grids for needle axis localization.\n",
    "        # - Median filter\n",
    "        median_filter = cv2.medianBlur(gabor_output, 7)\n",
    "        # - automatic thresholding\n",
    "        threshold = cv2.threshold(median_filter, 250, 255, cv2.THRESH_BINARY)[1]\n",
    "        # - morphological operations\n",
    "        element = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "        eroded = cv2.erode(threshold, element)\n",
    "        dilated = cv2.dilate(eroded, element)\n",
    "        #############################################################\n",
    "        \n",
    "        #Hough Line Transforms\n",
    "        #############################################################\n",
    "        # houghline = line_creation(dilated, resized_frame)\n",
    "        houghline = line_creation2(dilated, resized_frame)\n",
    "        houghcircle = needle_tip_estimation(dilated, resized_frame)\n",
    "\n",
    "        #############################################################\n",
    "        \n",
    "        #Overlaying segmentations onto B-mode image\n",
    "        #############################################################################################\n",
    "        # fgmaskV2_color = cv2.applyColorMap(bbox, cv2.COLORMAP_INFERNO)\n",
    "        # resized_frame_revert = cv2.cvtColor(resized_frame, cv2.COLOR_GRAY2RGB)\n",
    "        # overlay = cv2.addWeighted(resized_frame_revert, 0.5, fgmaskV2_color, 0.5, 1.0)\n",
    "        # cv2.imshow(\"Bmode Overlay\", overlay)\n",
    "        ###########################################################################################\n",
    "\n",
    "        # Debugging Statements\n",
    "        # cv2.imshow('normal frame', resized_frame)\n",
    "        # cv2.imshow('ROI frame', ROI_image)\n",
    "        # cv2.imshow('thresholding', thresh)\n",
    "        # cv2.imshow('Morphological Operations', skel_image)\n",
    "        # cv2.imshow('Canny Edge Detection', canny)\n",
    "        # cv2.imshow('Object Detection', bbox)\n",
    "        # cv2.imshow('Paper Algorithm', dilated)\n",
    "        # cv2.imshow('Hough Line Transform', houghline)\n",
    "        # cv2.imshow('Needle tip Estimation', houghcircle)\n",
    "        \n",
    "        #Saving comparison frames as gif \n",
    "        resized_frame = cv2.cvtColor(resized_frame, cv2.COLOR_GRAY2BGR)\n",
    "        line = cv2.cvtColor(houghline, cv2.COLOR_RGB2BGR)\n",
    "        algorithm = cv2.cvtColor(dilated, cv2.COLOR_GRAY2BGR)\n",
    "        tip = cv2.cvtColor(houghcircle, cv2.COLOR_RGB2BGR)\n",
    "        stack = np.hstack((resized_frame, line, tip))\n",
    "        cv2.imshow(\"stacked\", stack)\n",
    "        image_lst.append(stack)\n",
    "\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(frame_rate) & 0xFF == ord('q'): #original waitkey is 25\n",
    "            break\n",
    "    \n",
    "    #Break out of loop if video is done\n",
    "    else:\n",
    "        break  \n",
    "\n",
    "vc.release() #Release the video capture object\n",
    "\n",
    "# Close window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "The directory 'c:\\\\Users\\\\ezhon\\\\OneDrive\\\\Desktop\\\\Git_ultrasound\\\\MQP_Needle_Insertion\\\\Outputs' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Saving Video as GIF\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mimageio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmimsave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOutputs/V3_4_video.gif\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_lst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\imageio\\v2.py:494\u001b[0m, in \u001b[0;36mmimwrite\u001b[1;34m(uri, ims, format, **kwargs)\u001b[0m\n\u001b[0;32m    492\u001b[0m imopen_args \u001b[38;5;241m=\u001b[39m decypher_format_arg(\u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m    493\u001b[0m imopen_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 494\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwI\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mimopen_args\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mwrite(ims, is_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\imageio\\core\\imopen.py:113\u001b[0m, in \u001b[0;36mimopen\u001b[1;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m     request\u001b[38;5;241m.\u001b[39mformat_hint \u001b[38;5;241m=\u001b[39m format_hint\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mio_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<bytes>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(uri, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m uri\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# fast-path based on plugin\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# (except in legacy mode)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\imageio\\core\\request.py:247\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[1;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Request.Mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# Parse what was given\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# Set extension\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extension \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\imageio\\core\\request.py:412\u001b[0m, in \u001b[0;36mRequest._parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    410\u001b[0m dn \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(fn)\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(dn):\n\u001b[1;32m--> 412\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe directory \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m dn)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: The directory 'c:\\\\Users\\\\ezhon\\\\OneDrive\\\\Desktop\\\\Git_ultrasound\\\\MQP_Needle_Insertion\\\\Outputs' does not exist"
     ]
    }
   ],
   "source": [
    "# #Saving Video as GIF\n",
    "# imageio.mimsave('Outputs/V3_4_video.gif', image_lst, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
